<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Nyle Siddiqui</title>

    <meta name="author" content="Nyle Siddiqui">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Nyle Siddiqui
                </p>
                <p>I'm a 3rd-year Ph.D student at the  <a href="https://www.crcv.ucf.edu/">Center for Research in Computer Vision</a> at the University of Central Florida advised by Dr. Mubarak Shah. I am also a NSF GRFP 2024 Honorable Mention.</a>
                </p>
                <p style="text-align:center">
                  <a href="mailto:ny525072@ucf.edu">Email</a> &nbsp;/&nbsp;
                  <a href="CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=6ItMbGgAAAAJ&hl=en&authuser=1">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/NyleSiddiqui">Github</a> &nbsp;/&nbsp;
		  <a href="https://www.linkedin.com/in/nyle-siddiqui-b57828198/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/headshot.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research broadly spans the field of computer vision, with specific interests including generative AI, diffusion models, action recognition, person recognition, and representation learning. You can check out my selected papers below, with important papers <span style="background-color: #ffffd0;">highlighted</span>.

              </p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/AAAI24.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28290">
          <span class="papertitle">DVANet: Disentantgling View and Action Features for Multi-View Action Recognition</span>
        </a>
         <br>
        <strong>Nyle Siddiqui</strong>, 
        Praveen Tirupattur,  
        Mubarak Shah.
        <br>
        <em>AAAI Conference on Artificial Intelligence, Main Technical Track (<strong>AAAI</strong>)</em>, 2024
        <br>
       	<a href="https://arxiv.org/abs/2312.05719">paper</a> &nbsp/&nbsp <a href="https://github.com/NyleSiddiqui/MultiView_Actions">code</a> &nbsp/&nbsp <a href="https://nylesiddiqui.github.io/DVANet_webpage">project page</a>
	        <p></p>
	        <p>
	        We propose a novel transformer decoder-based architecture in tandem with two supervised contrastive losses for multi-view action recognition. By disentangling the view-relevant features from action-relevant features, we enable our model to learn action features that are robust to change in viewpoints. We show that changes in viewpoint impart perturbations on learned action features, and thus, disentangling these perturbations improves overall action recognition performance.
	        </p>
      </td>
    </tr>

<tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/CVPR-model-3.png' width=180>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
       <!-- <a href="https://smerf-3d.github.io/"> -->
          <span class="papertitle">DLCR: Leveraging Diffusion and Large Language Models for Effective Clothes-Changing Re-Identification</span>
        </a>
         <br>
        <strong>Nyle Siddiqui</strong>, 
        Alin Croitoru,
	Gaurav Kumar Nayak,
	Radu Tudor Ionescu,
        Mubarak Shah.
        <br>
        <em>IEEE/CVF Winter Conference on Applications of Computer Vision, Main Algorithms Track (<strong>WACV</strong>)</em>, 2025
        <br>
       	<!-- <a href="https://google.com">paper</a> &nbsp/&nbsp <a href="https://google.com">code</a> &nbsp/&nbsp <a href="https://google.com">project page</a> -->
	        <p></p>
	        <p>
		We propose a generative data expansion framework via diffusion for clothes-changing person Re-ID, which leverages pre-trained diffusion models and large language models to accurately generate images of individuals with different clothing attires. We address the challenges faced by CC-ReID models due to the limited clothing diversity in current CC-ReID datasets by genereating additional synthetic data that increases clothing diversity while preserving important personal features in the generated images. We also introduce two novel CC-ReID training strategies: progressive learning and test-time prediction refinement. Notably, training certain models with data generated by DLCR on the PRCC dataset resulted in improvements of up to 11.3% improvement in top-1 accuracy, with additonal enhanced performance on out-of-distribution test data.
	        </p>
      </td>
    </tr>

     <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/make.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.mdpi.com/2504-4990/4/2/23">
          <span class="papertitle">Machine and Deep Learning Applications to Mouse Dynamics for Continuous User Authentication</span>
        </a>
         <br>
        <strong>Nyle Siddiqui</strong>, 
        Rushit Dave,  
        Mounika Vanamala,
	Naeem Seliya.
        <br>
        <em>MDPI Journal of Machine Learning and Knowledge Extraction (<strong>MAKE</strong>)</em>, 2022
        <br>
	<em><strong><font color="red">(4th most cited MAKE paper in 2022)</font></strong></em>
	<br>
       	<a href="https://www.mdpi.com/2504-4990/4/2/23">paper</a> &nbsp &nbsp
	        <p></p>
	        <p>
	        </p>
      </td>
    </tr>

     
     <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/teaser.png' width=180>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
       <!-- <a href="https://smerf-3d.github.io/"> -->
          <span class="papertitle">StretchySnake: A Flexible VideoMamba for Short and Long Form Action Recognition </span>
        </a>
         <br>
        <strong>Nyle Siddiqui</strong>, 
        Rohit Gupta,
	Swetha Sirnam,
        Mubarak Shah.
        <br>
        <em>Under Review </em>
        <br>
       	<!-- <a href="https://google.com">paper</a> &nbsp/&nbsp <a href="https://google.com">code</a> &nbsp/&nbsp <a href="https://google.com">project page</a> -->
	        <p></p>
	        <p>
		Currenly under review. We instill VideoMamba with spatio-temporal flexibility and shows it performs better on a variety of action recognition tasks.
	        </p>
      </td>
    </tr>

		  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards / Recognitions</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
	  <td style="padding:20px;width:25%;text-align:center;vertical-align:middle"><img src="images/trophy.png" width="50%" alt="Trophy Image"></td>
				
          <td width="75%" valign="center">
		    <div>
		        <a href="https://www.research.gov/grfp/AwardeeList.do?method=loadAwardeeList">
		            <strong>NSF GRFP Honorable Mention</strong>, 2024 
		        </a>
		    </div>

		  <div>
<!-- 		        <a href="#"> -->
		    <strong>ORCGS Doctoral Fellowship,</strong> 2022-2026
<!-- 		        </a> -->
	   	 </div>
		<br>
		</td>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Reviewing Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
		<a href="https://iclr.cc/Conferences/2025">Reviewer, ICLR 2025</a><br>	
		<a href="https://neurips.cc/Conferences/2024">Reviewer, NeurIPS 2024</a><br>	
		<a href="https://iccv2023.thecvf.com/">Reviewer, ICCV 2023</a><br>
              <br>
              <br>
             
            </td>
          </tr>	


		  
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Mentor in NSF-REU</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;text-align:center;vertical-align:middle"><img src="images/NSF_svg.png" width="50%" alt="NSF Image"></td>
            <td width="75%" valign="center">
		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2023/">Philomina Ekezie, REU 2023</a>
		<br>
		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2024/">Joseph Ho, REU 2024</a>
	        <br>
		<a href="https://www.crcv.ucf.edu/nsf-projects/reu/reu-2024/">Franco Vidal, REU 2024</a>
		<br>
            </td>
          </tr>	
					
        </tbody></table>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
